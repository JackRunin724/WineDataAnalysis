import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
from sklearn.utils import resample
from sklearn.preprocessing import StandardScaler
from ctgan import CTGAN
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import wasserstein_distance, ks_2samp
import umap.umap_ as umap

class DataAugmentation:
    """æ”¯æŒå¤šç§æ•°æ®å¢å¼ºæ–¹æ³•åŠè¯„ä»·ç›¸å…³æ€§çš„ç±»"""
    
    def __init__(self, x, y):
        self.x = x
        self.y = y
        self.x_aug = None
        self.y_aug = None
        self.x_combined = None
        self.y_combined = None

    def show_data(self):
        """æ˜¾ç¤ºä¸€ä¸‹å½“å‰çš„æ•°æ®"""
        print("\n" + "="*50)
        print("åŸå§‹ç‰¹å¾æ•°æ® (x):")
        print("="*50)
        print(f"å½¢çŠ¶: {self.x.shape}")
        print(self.x.head())
        
        print("\n" + "="*50)
        print("åŸå§‹ç›®æ ‡å˜é‡ (y):")
        print("="*50)
        print(f"å½¢çŠ¶: {self.y.shape}")
        print(self.y.head())
        
        if self.x_aug is not None:
            print("\n" + "="*50)
            print("å¢å¼ºåçš„ç‰¹å¾æ•°æ® (x_aug):")
            print("="*50)
            print(f"å½¢çŠ¶: {self.x_aug.shape}")
            print(self.x_aug.head())
            
        if self.y_aug is not None:
            print("\n" + "="*50)
            print("å¢å¼ºåçš„ç›®æ ‡å˜é‡ (y_aug):")
            print("="*50)
            print(f"å½¢çŠ¶: {self.y_aug.shape}")
            print(self.y_aug.head())
        
        if self.x_combined is not None:
            print("\n" + "="*50)
            print("åˆå¹¶åçš„ç‰¹å¾æ•°æ® (x_combined):")
            print("="*50)
            print(f"å½¢çŠ¶: {self.x_combined.shape}")
            print("å‰5è¡ŒåŸå§‹æ•°æ® + å5è¡Œå¢å¼ºæ•°æ®:")
            print(pd.concat([self.x_combined.head(), self.x_combined.tail()]))
            
        if self.y_combined is not None:
            print("\n" + "="*50)
            print("åˆå¹¶åçš„ç›®æ ‡å˜é‡ (y_combined):")
            print("="*50)
            print(f"å½¢çŠ¶: {self.y_combined.shape}")
            print("å‰5è¡ŒåŸå§‹æ•°æ® + å5è¡Œå¢å¼ºæ•°æ®:")
            print(pd.concat([self.y_combined.head(), self.y_combined.tail()]))

    def apply_smogn(self):
        """SMOGN"""
        print("åº”ç”¨SMOGNæ•°æ®å¢å¼º...")
        print("è¯¥æ–¹æ³•åŸºæœ¬è¡Œä¸é€š")
        return None, None

    def apply_bootstrapping(self, n_samples=100, noise_scale=0.1, random_state=42):
        """Bootstrappingæ•°æ®å¢å¼º"""
        print("åº”ç”¨ Bootstrapé‡é‡‡æ · + é«˜æ–¯å™ªå£° è¿›è¡Œæ•°æ®å¢å¼º...")

        x, y = self.x, self.y
        
        # è®°å½•åŸå§‹åˆ—å
        x_cols = x.columns.tolist()
        y_cols = y.columns.tolist()
    
        # æ ‡å‡†åŒ–æ•°æ®
        scaler_x = StandardScaler()
        scaler_y = StandardScaler()
        x_scaled = scaler_x.fit_transform(x)
        y_scaled = scaler_y.fit_transform(y)
        
        # Bootstrapé‡é‡‡æ ·
        x_resampled, y_resampled = resample(
            x_scaled, y_scaled, 
            n_samples=n_samples, 
            replace=True,
            random_state=random_state
        )
        
        # æ·»åŠ é«˜æ–¯å™ªå£°
        np.random.seed(random_state)
        x_noise = np.random.normal(scale=noise_scale, size=x_resampled.shape)
        y_noise = np.random.normal(scale=noise_scale, size=y_resampled.shape)
        
        # åˆå¹¶å™ªå£°
        x_aug = x_resampled + x_noise
        y_aug = y_resampled + y_noise
        
        # é€†æ ‡å‡†åŒ–
        x_aug = scaler_x.inverse_transform(x_aug)
        y_aug = scaler_y.inverse_transform(y_aug)
        
        # è½¬å›DataFrame
        x_aug = pd.DataFrame(x_aug, columns=x_cols)
        y_aug = pd.DataFrame(y_aug, columns=y_cols)
        
        print(f"æ•°æ®å¢å¼ºå®Œæˆ: {len(x)} -> {len(x_aug)} æ ·æœ¬")
        
        # æ›´æ–°ç±»å±æ€§
        self.x_aug = x_aug
        self.y_aug = y_aug
        self.x_combined = pd.concat([x, x_aug], ignore_index=True)
        self.y_combined = pd.concat([y, y_aug], ignore_index=True)
        
        return x_aug, y_aug

    def apply_gans(self, n_samples=100, epochs=100, batch_size=100):
        """GANs (CTGAN) æ•°æ®å¢å¼º"""
        print("åº”ç”¨å…¨ç»´åº¦CTGANæ•°æ®å¢å¼º...")

        x, y = self.x, self.y
        
        # åˆå¹¶ç‰¹å¾å’Œç›®æ ‡
        data = pd.concat([x, y], axis=1)
        original_cols = data.columns.tolist()
        
        # è¯†åˆ«è¿ç»­åˆ—
        continuous_cols = [col for col in data.columns if pd.api.types.is_numeric_dtype(data[col])]
        
        # å½’ä¸€åŒ–
        scaler = MinMaxScaler()
        data_scaled = pd.DataFrame(
            scaler.fit_transform(data),
            columns=data.columns
        )
        
        # é…ç½®CTGAN
        ctgan = CTGAN(
            epochs=epochs,
            batch_size=batch_size,
            generator_dim=(256, 256),
            discriminator_dim=(256, 256),
            pac=5,
            cuda=False,
            verbose=True
        )
        
        print("å¼€å§‹è®­ç»ƒGAN...")
        ctgan.fit(data_scaled, continuous_cols)
        
        # ç”Ÿæˆæ–°æ ·æœ¬
        print(f"ç”Ÿæˆ {n_samples} ä¸ªæ ·æœ¬...")
        synthetic_data = ctgan.sample(n_samples)
        
        # é€†å½’ä¸€åŒ–
        synthetic_data = pd.DataFrame(
            scaler.inverse_transform(synthetic_data),
            columns=original_cols
        )
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        x_cols = x.columns.tolist()
        y_cols = y.columns.tolist()
        x_aug = synthetic_data[x_cols]
        y_aug = synthetic_data[y_cols]
        
        print(f"ç”Ÿæˆå®Œæˆ: åŸå§‹æ•°æ® {len(x)} -> åˆæˆæ•°æ® {len(x_aug)}")
        print(f"ç›®æ ‡å˜é‡ç»´åº¦: {y_aug.shape[1]}")
        
        # æ›´æ–°ç±»å±æ€§
        self.x_aug = x_aug
        self.y_aug = y_aug
        self.x_combined = pd.concat([x, x_aug], ignore_index=True)
        self.y_combined = pd.concat([y, y_aug], ignore_index=True)

        return x_aug, y_aug

    def direct_quality_assessment(self):
        """ç›´æ¥è¯„ä¼°ç”Ÿæˆæ•°æ®çš„è´¨é‡"""
        if self.y_aug is None:
            print("è¯·å…ˆè¿›è¡Œæ•°æ®å¢å¼ºï¼")
            return None
            
        y_original = self.y.values if hasattr(self.y, 'values') else self.y
        y_synthetic = self.y_aug.values if hasattr(self.y_aug, 'values') else self.y_aug
        
        print("ç”Ÿæˆæ•°æ®è´¨é‡ç›´æ¥è¯„ä¼°")
        print("="*50)
        
        # 1. å‡å€¼ç›¸ä¼¼æ€§
        mean_original = np.mean(y_original, axis=0)
        mean_synthetic = np.mean(y_synthetic, axis=0)
        mean_correlation = np.corrcoef(mean_original, mean_synthetic)[0, 1]
        print(f"å‡å€¼ç›¸å…³æ€§: {mean_correlation:.4f}")
        
        # 2. æ ‡å‡†å·®ç›¸ä¼¼æ€§  
        std_original = np.std(y_original, axis=0)
        std_synthetic = np.std(y_synthetic, axis=0)
        std_correlation = np.corrcoef(std_original, std_synthetic)[0, 1]
        print(f"æ ‡å‡†å·®ç›¸å…³æ€§: {std_correlation:.4f}")
        
        # 3. åˆ†å¸ƒè·ç¦»è¯„ä¼°
        n_vars = min(10, y_original.shape[1])
        wasserstein_distances = []
        ks_pvalues = []
        
        for i in range(n_vars):
            w_dist = wasserstein_distance(y_original[:, i], y_synthetic[:, i])
            wasserstein_distances.append(w_dist)
            
            ks_stat, ks_pval = ks_2samp(y_original[:, i], y_synthetic[:, i])
            ks_pvalues.append(ks_pval)
        
        print(f"å¹³å‡Wassersteinè·ç¦»: {np.mean(wasserstein_distances):.4f}")
        print(f"KSæ£€éªŒå¹³å‡på€¼: {np.mean(ks_pvalues):.4f}")
        
        # å¯è§†åŒ–
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))
        
        # å‡å€¼ä¸€è‡´æ€§
        ax1.scatter(mean_original, mean_synthetic, alpha=0.6)
        ax1.plot([mean_original.min(), mean_original.max()], 
                [mean_original.min(), mean_original.max()], 'r--')
        ax1.set_xlabel('åŸå§‹æ•°æ®å‡å€¼')
        ax1.set_ylabel('ç”Ÿæˆæ•°æ®å‡å€¼')
        ax1.set_title('å‡å€¼ä¸€è‡´æ€§')
        
        # æ–¹å·®ä¸€è‡´æ€§
        ax2.scatter(std_original, std_synthetic, alpha=0.6)
        ax2.plot([std_original.min(), std_original.max()], 
                [std_original.min(), std_original.max()], 'r--')
        ax2.set_xlabel('åŸå§‹æ•°æ®æ ‡å‡†å·®')
        ax2.set_ylabel('ç”Ÿæˆæ•°æ®æ ‡å‡†å·®')
        ax2.set_title('æ–¹å·®ä¸€è‡´æ€§')
        
        # åˆ†å¸ƒè·ç¦»
        ax3.bar(range(n_vars), wasserstein_distances)
        ax3.set_xlabel('ç›®æ ‡å˜é‡ç´¢å¼•')
        ax3.set_ylabel('Wassersteinè·ç¦»')
        ax3.set_title('åˆ†å¸ƒè·ç¦»è¯„ä¼°')
        
        plt.tight_layout()
        plt.show()

        return {
            'mean_correlation': mean_correlation,
            'std_correlation': std_correlation,
            'wasserstein_distances': wasserstein_distances,
            'ks_pvalues': ks_pvalues
        }

    def comprehensive_visualization(self):
        """ç»¼åˆå¯è§†åŒ–åˆ†æ"""
        if self.y_aug is None:
            print("è¯·å…ˆè¿›è¡Œæ•°æ®å¢å¼ºï¼")
            return None
            
        y_original = self.y.values if hasattr(self.y, 'values') else self.y
        y_synthetic = self.y_aug.values if hasattr(self.y_aug, 'values') else self.y_aug
        
        y_combined = np.vstack([y_original, y_synthetic])
        labels = ['åŸå§‹y'] * len(y_original) + ['ç”Ÿæˆy'] * len(y_synthetic)
        
        # ä¸‰ç§é™ç»´æ–¹æ³•
        reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=5)
        y_umap = reducer.fit_transform(y_combined)
        
        tsne = TSNE(n_components=2, random_state=42, perplexity=5)
        y_tsne = tsne.fit_transform(y_combined)
        
        pca = PCA(n_components=2)
        y_pca = pca.fit_transform(y_combined)
        
        # å¯è§†åŒ–
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))
        
        # UMAP
        for label, color in zip(['åŸå§‹y', 'ç”Ÿæˆy'], ['blue', 'red']):
            mask = np.array(labels) == label
            ax1.scatter(y_umap[mask, 0], y_umap[mask, 1], c=color, alpha=0.7, label=label, s=50)
        ax1.set_title('UMAP - å…¨å±€ç»“æ„è¯„ä¼°')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # t-SNE
        for label, color in zip(['åŸå§‹y', 'ç”Ÿæˆy'], ['blue', 'red']):
            mask = np.array(labels) == label
            ax2.scatter(y_tsne[mask, 0], y_tsne[mask, 1], c=color, alpha=0.7, label=label, s=50)
        ax2.set_title('t-SNE - å±€éƒ¨ç»“æ„åˆ†æ')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # PCA
        for label, color in zip(['åŸå§‹y', 'ç”Ÿæˆy'], ['blue', 'red']):
            mask = np.array(labels) == label
            ax3.scatter(y_pca[mask, 0], y_pca[mask, 1], c=color, alpha=0.7, label=label, s=50)
        ax3.set_title(f'PCA (è§£é‡Šæ–¹å·®: {np.sum(pca.explained_variance_ratio_):.3f})')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return y_umap, y_tsne, y_pca

    # def save_to_csv(self, save_dir=".", prefix=None, include_timestamp=True):
    #     """
    #     ä¿å­˜å¢å¼ºæ•°æ®å’Œåˆå¹¶æ•°æ®åˆ°CSVæ–‡ä»¶
        
    #     å‚æ•°:
    #         save_dir: ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
    #         prefix: æ–‡ä»¶åå‰ç¼€
    #         include_timestamp: æ˜¯å¦åœ¨æ–‡ä»¶åä¸­åŒ…å«æ—¶é—´æˆ³
    #     """
    #     if self.x_aug is None or self.y_aug is None:
    #         print("è­¦å‘Šï¼šå°šæœªè¿›è¡Œæ•°æ®å¢å¼ºï¼Œæ— æ³•ä¿å­˜æ•°æ®ï¼")
    #         return False
        
    #     try:
    #         # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    #         os.makedirs(save_dir, exist_ok=True)
            
    #         # ç”Ÿæˆæ–‡ä»¶åå‰ç¼€
    #         if prefix is None:
    #             prefix = "augmented_data"
            
    #         # ç”Ÿæˆæ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
    #         timestamp = ""
    #         if include_timestamp:
    #             if self.augmentation_time is None:
    #                 self.augmentation_time = datetime.now()
    #             timestamp = f"_{self.augmentation_time.strftime('%Y%m%d_%H%M%S')}"
            
    #         # ç”Ÿæˆæ–‡ä»¶å
    #         files_info = {
    #             'original_x': f"{prefix}_original_x{timestamp}.csv",
    #             'original_y': f"{prefix}_original_y{timestamp}.csv",
    #             'augmented_x': f"{prefix}_augmented_x{timestamp}.csv", 
    #             'augmented_y': f"{prefix}_augmented_y{timestamp}.csv",
    #             'combined_x': f"{prefix}_combined_x{timestamp}.csv",
    #             'combined_y': f"{prefix}_combined_y{timestamp}.csv",
    #             'metadata': f"{prefix}_metadata{timestamp}.txt"
    #         }
            
    #         # ä¿å­˜åŸå§‹æ•°æ®
    #         self.x.to_csv(os.path.join(save_dir, files_info['original_x']), index=False)
    #         self.y.to_csv(os.path.join(save_dir, files_info['original_y']), index=False)
    #         print(f"âœ“ åŸå§‹ç‰¹å¾æ•°æ®ä¿å­˜è‡³: {files_info['original_x']}")
    #         print(f"âœ“ åŸå§‹ç›®æ ‡æ•°æ®ä¿å­˜è‡³: {files_info['original_y']}")
            
    #         # ä¿å­˜å¢å¼ºæ•°æ®
    #         self.x_aug.to_csv(os.path.join(save_dir, files_info['augmented_x']), index=False)
    #         self.y_aug.to_csv(os.path.join(save_dir, files_info['augmented_y']), index=False)
    #         print(f"âœ“ å¢å¼ºç‰¹å¾æ•°æ®ä¿å­˜è‡³: {files_info['augmented_x']}")
    #         print(f"âœ“ å¢å¼ºç›®æ ‡æ•°æ®ä¿å­˜è‡³: {files_info['augmented_y']}")
            
    #         # ä¿å­˜åˆå¹¶æ•°æ®
    #         self.x_combined.to_csv(os.path.join(save_dir, files_info['combined_x']), index=False)
    #         self.y_combined.to_csv(os.path.join(save_dir, files_info['combined_y']), index=False)
    #         print(f"âœ“ åˆå¹¶ç‰¹å¾æ•°æ®ä¿å­˜è‡³: {files_info['combined_x']}")
    #         print(f"âœ“ åˆå¹¶ç›®æ ‡æ•°æ®ä¿å­˜è‡³: {files_info['combined_y']}")
            
    #         # ä¿å­˜å…ƒæ•°æ®ä¿¡æ¯
    #         self._save_metadata(os.path.join(save_dir, files_info['metadata']))
    #         print(f"âœ“ å…ƒæ•°æ®ä¿¡æ¯ä¿å­˜è‡³: {files_info['metadata']}")
            
    #         # ä¿å­˜æ–‡ä»¶åˆ—è¡¨ä¿¡æ¯
    #         self._save_file_list(save_dir, files_info, prefix)
            
    #         print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°ç›®å½•: {os.path.abspath(save_dir)}")
    #         return True
            
    #     except Exception as e:
    #         print(f"âŒ ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")
    #         return False

    # def save_visualization(self, save_dir=".", prefix=None, dpi=300):
    #     """
    #     ä¿å­˜å¯è§†åŒ–å›¾è¡¨åˆ°æ–‡ä»¶
        
    #     å‚æ•°:
    #         save_dir: ä¿å­˜ç›®å½•
    #         prefix: æ–‡ä»¶åå‰ç¼€
    #         dpi: å›¾ç‰‡åˆ†è¾¨ç‡
    #     """
    #     if self.y_aug is None:
    #         print("è­¦å‘Šï¼šå°šæœªè¿›è¡Œæ•°æ®å¢å¼ºï¼Œæ— æ³•ä¿å­˜å¯è§†åŒ–ï¼")
    #         return False
        
    #     try:
    #         os.makedirs(save_dir, exist_ok=True)
            
    #         if prefix is None:
    #             prefix = "visualization"
            
    #         timestamp = ""
    #         if self.augmentation_time:
    #             timestamp = f"_{self.augmentation_time.strftime('%Y%m%d_%H%M%S')}"
            
    #         # ç”Ÿæˆè´¨é‡è¯„ä¼°å›¾è¡¨
    #         plt.figure(figsize=(12, 4))
            
    #         y_original = self.y.values if hasattr(self.y, 'values') else self.y
    #         y_synthetic = self.y_aug.values if hasattr(self.y_aug, 'values') else self.y_aug
            
    #         # å‡å€¼ä¸€è‡´æ€§
    #         mean_original = np.mean(y_original, axis=0)
    #         mean_synthetic = np.mean(y_synthetic, axis=0)
            
    #         plt.subplot(1, 3, 1)
    #         plt.scatter(mean_original, mean_synthetic, alpha=0.6)
    #         plt.plot([mean_original.min(), mean_original.max()], 
    #                 [mean_original.min(), mean_original.max()], 'r--')
    #         plt.xlabel('åŸå§‹æ•°æ®å‡å€¼')
    #         plt.ylabel('ç”Ÿæˆæ•°æ®å‡å€¼')
    #         plt.title('å‡å€¼ä¸€è‡´æ€§')
            
    #         # æ–¹å·®ä¸€è‡´æ€§
    #         std_original = np.std(y_original, axis=0)
    #         std_synthetic = np.std(y_synthetic, axis=0)
            
    #         plt.subplot(1, 3, 2)
    #         plt.scatter(std_original, std_synthetic, alpha=0.6)
    #         plt.plot([std_original.min(), std_original.max()], 
    #                 [std_original.min(), std_original.max()], 'r--')
    #         plt.xlabel('åŸå§‹æ•°æ®æ ‡å‡†å·®')
    #         plt.ylabel('ç”Ÿæˆæ•°æ®æ ‡å‡†å·®')
    #         plt.title('æ–¹å·®ä¸€è‡´æ€§')
            
    #         # åˆ†å¸ƒè·ç¦»
    #         n_vars = min(10, y_original.shape[1])
    #         wasserstein_distances = []
    #         for i in range(n_vars):
    #             w_dist = wasserstein_distance(y_original[:, i], y_synthetic[:, i])
    #             wasserstein_distances.append(w_dist)
            
    #         plt.subplot(1, 3, 3)
    #         plt.bar(range(n_vars), wasserstein_distances)
    #         plt.xlabel('ç›®æ ‡å˜é‡ç´¢å¼•')
    #         plt.ylabel('Wassersteinè·ç¦»')
    #         plt.title('åˆ†å¸ƒè·ç¦»è¯„ä¼°')
            
    #         plt.tight_layout()
    #         plt.savefig(os.path.join(save_dir, f"{prefix}_quality_assessment{timestamp}.png"), 
    #                    dpi=dpi, bbox_inches='tight')
    #         plt.close()
            
    #         print(f"âœ“ è´¨é‡è¯„ä¼°å›¾è¡¨ä¿å­˜è‡³: {prefix}_quality_assessment{timestamp}.png")
            
    #         # ä¿å­˜ç»¼åˆå¯è§†åŒ–ï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
    #         try:
    #             # è¿™é‡Œå¯ä»¥è°ƒç”¨comprehensive_visualizationå¹¶ä¿å­˜ç»“æœ
    #             pass
    #         except:
    #             pass
                
    #         return True
            
    #     except Exception as e:
    #         print(f"âŒ ä¿å­˜å¯è§†åŒ–æ—¶å‡ºé”™: {e}")
    #         return False

    # def quick_save(self, description=""):
    #     """
    #     å¿«é€Ÿä¿å­˜æ–¹æ³•ï¼ˆä½¿ç”¨é»˜è®¤è®¾ç½®ï¼‰
        
    #     å‚æ•°:
    #         description: æ•°æ®æè¿°ï¼Œç”¨äºæ–‡ä»¶å
    #     """
    #     if description:
    #         prefix = f"augmented_{description}"
    #     else:
    #         prefix = "augmented_data"
        
    #     # è®¾ç½®å¢å¼ºæ—¶é—´
    #     self.augmentation_time = datetime.now()
        
    #     # ä¿å­˜æ•°æ®
    #     success1 = self.save_to_csv(prefix=prefix)
        
    #     # ä¿å­˜å¯è§†åŒ–
    #     success2 = self.save_visualization(prefix=prefix)
        
    #     return success1 and success2


# def main():
#     """ä¸»å‡½æ•°ç¤ºä¾‹"""
#     print("=== æ•°æ®å¢å¼ºç³»ç»Ÿæ¼”ç¤º ===")
    
#     # ç¤ºä¾‹ï¼šåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®ï¼‰
#     np.random.seed(42)

#     n_samples = 20
#     n_features = 2
#     n_targets = 58
    
#     # åˆ›å»ºç¤ºä¾‹æ•°æ®
#     x = pd.DataFrame(np.random.randn(n_samples, n_features), columns=['feature1', 'feature2'])
#     y = pd.DataFrame(np.random.randn(n_samples, n_targets), columns=[f'target_{i}' for i in range(n_targets)])
    
#     print(f"åŸå§‹æ•°æ®å½¢çŠ¶: x={x.shape}, y={y.shape}")
    
#     # åˆå§‹åŒ–æ•°æ®å¢å¼ºç±»
#     da = DataAugmentation(x, y)
    
#     # æ˜¾ç¤ºåŸå§‹æ•°æ®
#     print("\n1. åŸå§‹æ•°æ®æ¦‚è§ˆ:")
#     da.show_data()
    
#     # æ–¹æ³•1: ä½¿ç”¨GANsè¿›è¡Œæ•°æ®å¢å¼º
#     print("\n2. ä½¿ç”¨GANsè¿›è¡Œæ•°æ®å¢å¼º:")
#     x_aug, y_aug = da.apply_gans(n_samples=50, epochs=50, batch_size=20)
    
#     # æ˜¾ç¤ºå¢å¼ºåçš„æ•°æ®
#     print("\n3. å¢å¼ºåæ•°æ®æ¦‚è§ˆ:")
#     da.show_data()
    
#     # è´¨é‡è¯„ä¼°
#     print("\n4. æ•°æ®è´¨é‡è¯„ä¼°:")
#     quality_results = da.direct_quality_assessment()
    
#     # å¯è§†åŒ–åˆ†æ
#     print("\n5. ç»¼åˆå¯è§†åŒ–åˆ†æ:")
#     da.comprehensive_visualization()
    
#     print("\n=== æ¼”ç¤ºå®Œæˆ ===")

def main():
    """ç®€åŒ–ç‰ˆä¸»å‡½æ•°ç”¨äºæµ‹è¯•"""
    print("=== æ•°æ®å¢å¼ºç³»ç»Ÿæµ‹è¯• ===")
    
    # åˆ›å»ºæ›´å°çš„æµ‹è¯•æ•°æ®
    np.random.seed(42)
    n_samples = 10  # å‡å°‘æ ·æœ¬æ•°
    n_features = 2
    n_targets = 5   # å‡å°‘ç›®æ ‡å˜é‡æ•°
    
    x = pd.DataFrame(np.random.randn(n_samples, n_features), columns=['feature1', 'feature2'])
    y = pd.DataFrame(np.random.randn(n_samples, n_targets), columns=[f'target_{i}' for i in range(n_targets)])
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: x={x.shape}, y={y.shape}")
    
    # åˆå§‹åŒ–æ•°æ®å¢å¼ºç±»
    da = DataAugmentation(x, y)
    
    # å…ˆå°è¯•ç®€å•çš„ bootstrapping æ–¹æ³•
    print("\n1. ä½¿ç”¨ Bootstrapping è¿›è¡Œæ•°æ®å¢å¼º:")
    x_aug, y_aug = da.apply_bootstrapping(n_samples=5)  # è¿™ä¸ªæ–¹æ³•æ›´å¿«
    
    # æ˜¾ç¤ºæ•°æ®
    print("\n2. å¢å¼ºåæ•°æ®æ¦‚è§ˆ:")
    da.show_data()
    
    # è´¨é‡è¯„ä¼°
    print("\n3. æ•°æ®è´¨é‡è¯„ä¼°:")
    quality_results = da.direct_quality_assessment()
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")


if __name__ == "__main__":
    print(1)
    main()